{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regression_Gradient Descent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXNqxOCvY+vyTc7eXc997x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohan75489/Mohan75489/blob/main/Linear_Regression_Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "q4uflc11Z4-q",
        "outputId": "23c58d0f-1465-4dd4-f9f4-99ef0629383b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DataPoint1: 73,62,44 gives 56,70\\nDataPoint1: 90,84,60 gives 82,104\\nDataPoint1: 71,155,58 gives 117,143\\nDataPoint1: 109,40,32 gives 20,42\\nDataPoint1: 69,99,74 gives 106,123'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#Predicting a dimension model\n",
        "#2 dependent & 3 independent variables for a data point\n",
        "'''DataPoint1: 73,62,44 gives 56,70\n",
        "DataPoint1: 90,84,60 gives 82,104\n",
        "DataPoint1: 71,155,58 gives 117,143\n",
        "DataPoint1: 109,40,32 gives 20,42\n",
        "DataPoint1: 69,99,74 gives 106,123'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#consider it as linear regression problem\n",
        "#outputs (dependent variable) depends on each input(independent variables) with certain wait and a bias\n",
        "'''Dim1=w11*dim1+w12*dim2+w13*dim3+b1\n",
        "Dim2=w21*dim1+w22*dim2+w23*dim3+b2'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Wci0pnKWaqCK",
        "outputId": "f1d946b7-d271-486f-f9fc-b8d9342e66cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dim1=w11*dim1+w12*dim2+w13*dim3\\nDim2=w21*dim1+w22*dim2+w23*dim3'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing both numpy and PyTorch librarires\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "T4jeOAnNdeB9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keeping one data point for checking model predictions.\n",
        "Remaining 4 data points for training the model."
      ],
      "metadata": {
        "id": "2mE_KNord_Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#taking inputs as numpy arrays and conversion to torch tensors\n",
        "inputs = np.array([[73,62,44],[90,84,60],[71,155,58],[109,40,32]],dtype='float32')\n",
        "targets = np.array([[56,70],[82,104],[117,143],[20,42]],dtype='float32')\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-EVsYOzdQR5",
        "outputId": "ebda9636-0767-4151-db3c-ee78f1e200ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  62.,  44.],\n",
            "        [ 90.,  84.,  60.],\n",
            "        [ 71., 155.,  58.],\n",
            "        [109.,  40.,  32.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 82., 104.],\n",
            "        [117., 143.],\n",
            "        [ 20.,  42.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating random weights and biases\n",
        "w = torch.randn(3,2, requires_grad=True) #beacause 3 rows and 2 columns\n",
        "b = torch.randn(2, requires_grad=True) #because 2 rows and 1 column\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QS3Aicje2Rg",
        "outputId": "bc656c63-4a02-483f-8fb8-c7b6e1f72159"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5103,  0.7170],\n",
            "        [-0.3340,  2.1479],\n",
            "        [-0.6228,  0.1922]], requires_grad=True)\n",
            "tensor([1.7046, 0.6569], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a function to take inputs and return outputs\n",
        "def model(x):\n",
        "    return x @ w +b"
      ],
      "metadata": {
        "id": "bY8MQohofi03"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting first time (obviously too much far from actual values)\n",
        "predict = model(inputs)\n",
        "print(predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjHQk1KlgrCA",
        "outputId": "853a15c8-84ae-41a1-deb5-9bf003df80ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -9.1587, 194.6206],\n",
            "        [-17.7977, 257.1374],\n",
            "        [-49.9631, 395.6314],\n",
            "        [ 24.0339, 170.8721]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#error or loss function (using mean sqaure error)\n",
        "def mse(t1,t2):\n",
        "      diff=t1-t2\n",
        "      return torch.sum(diff*diff)/diff.numel()"
      ],
      "metadata": {
        "id": "dCxYnqCohQK9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating loss using mse function created\n",
        "loss = mse(predict,targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWZnm82vh9k3",
        "outputId": "c6f54b7c-10f3-4d71-a50d-30439bad76d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(20188.7695, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loss is near to zero means model is predicting well (current model is too far from good)\n",
        "#compute gradients, it's slope of loss function with respect to it's dependents (weights and biases).\n",
        "loss.backward()\n",
        "print(w)\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSuKfGmViLqS",
        "outputId": "ce3061b7-0386-4c53-bdff-3b761a9452be"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5103,  0.7170],\n",
            "        [-0.3340,  2.1479],\n",
            "        [-0.6228,  0.1922]], requires_grad=True)\n",
            "tensor([[-6288.2676, 13715.8887],\n",
            "        [-9535.1924, 16225.6914],\n",
            "        [-4602.4053,  8362.0186]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adjusting weights and not calculating grads again (to increase efficiency)\n",
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "metadata": {
        "id": "r-71iRA-kWC-",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#new weights and biases\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "U0UfxV3hJvu9",
        "outputId": "4cb1c367-8888-4588-9f5d-d0ae15c80038",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5732,  0.5798],\n",
            "        [-0.2387,  1.9856],\n",
            "        [-0.5768,  0.1085]], requires_grad=True)\n",
            "tensor([1.7055, 0.6553], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one more iteration of loss calculation\n",
        "predict = model(inputs)\n",
        "loss = mse(predict, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "BUnXeeZYKbNe",
        "outputId": "29ae82fd-64a1-43e4-9d9f-36f855371a87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14051.3076, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe loss is decreased drastically from 20188 to 14051."
      ],
      "metadata": {
        "id": "Qt0KCLuhKxm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#runnning in a for loop to iterate loss function for 100 times (epochs)\n",
        "for i in range(100):\n",
        "    predict = model(inputs)\n",
        "    loss = mse(predict, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()"
      ],
      "metadata": {
        "id": "PGpMEunWKtig"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the new loss after epochs\n",
        "predict = model(inputs)\n",
        "loss = mse(predict, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "85LNh9BJLbS-",
        "outputId": "045d1c93-456a-4a0e-c49d-af5d0ec2e286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(202.1741, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can check accuracy by comparing targets and predictions\n",
        "print(targets)\n",
        "print(predict)"
      ],
      "metadata": {
        "id": "hCBEfAoZL_We",
        "outputId": "3ff42052-7215-48f5-8a55-e3742ba0c58b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 82., 104.],\n",
            "        [117., 143.],\n",
            "        [ 20.,  42.]])\n",
            "tensor([[ 51.7374,  64.5638],\n",
            "        [ 67.1953,  85.9993],\n",
            "        [113.7678, 155.9432],\n",
            "        [ 48.1984,  49.3038]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#seems good for some data points, probably it need 100 more epochs\n",
        "for i in range(100):\n",
        "    predict = model(inputs)\n",
        "    loss = mse(predict, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()"
      ],
      "metadata": {
        "id": "8iRR042PMOZN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model(inputs)\n",
        "loss = mse(predict,targets)\n",
        "print(loss)\n",
        "print(targets)\n",
        "print(predict)"
      ],
      "metadata": {
        "id": "l3ucsvzdM4Rm",
        "outputId": "c092e862-e25c-4e04-fd16-a7985aa03516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(135.0044, grad_fn=<DivBackward0>)\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 82., 104.],\n",
            "        [117., 143.],\n",
            "        [ 20.,  42.]])\n",
            "tensor([[ 49.7195,  65.9598],\n",
            "        [ 66.0113,  87.6554],\n",
            "        [123.0549, 151.9084],\n",
            "        [ 36.6851,  52.3474]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can refain it more, this time for 200 epochs with same learning rate\n",
        "for i in range(200):\n",
        "    predict = model(inputs)\n",
        "    loss = mse(predict, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()"
      ],
      "metadata": {
        "id": "I_7QquGuNHjV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model(inputs)\n",
        "loss = mse(predict,targets)\n",
        "print(loss)\n",
        "print(targets)\n",
        "print(predict)"
      ],
      "metadata": {
        "id": "CM8vXq1LNaJ_",
        "outputId": "3f5dd1da-e30d-4a8b-ba68-5a89589c0c86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(103.7898, grad_fn=<DivBackward0>)\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 82., 104.],\n",
            "        [117., 143.],\n",
            "        [ 20.,  42.]])\n",
            "tensor([[ 49.9876,  67.0929],\n",
            "        [ 67.2147,  89.4720],\n",
            "        [124.8090, 149.9828],\n",
            "        [ 32.0629,  52.0397]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "    predict = model(inputs)\n",
        "    loss = mse(predict, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()"
      ],
      "metadata": {
        "id": "fotUA-cUNcgm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model(inputs)\n",
        "loss = mse(predict,targets)\n",
        "print(loss)\n",
        "print(targets)\n",
        "print(predict)"
      ],
      "metadata": {
        "id": "vFZe_34bNjsG",
        "outputId": "5d1c3a7b-dfee-469f-9990-922fb612f63a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(32.0964, grad_fn=<DivBackward0>)\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 82., 104.],\n",
            "        [117., 143.],\n",
            "        [ 20.,  42.]])\n",
            "tensor([[ 53.4409,  70.1589],\n",
            "        [ 73.5686,  95.0636],\n",
            "        [121.2771, 146.7034],\n",
            "        [ 26.3148,  47.2312]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "    predict = model(inputs)\n",
        "    loss = mse(predict, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()"
      ],
      "metadata": {
        "id": "Atu3CJTxNmDa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model(inputs)\n",
        "loss = mse(predict,targets)\n",
        "print(loss)\n",
        "print(targets)\n",
        "print(predict)"
      ],
      "metadata": {
        "id": "8Ln5FsC0NrbR",
        "outputId": "35f33443-ab64-4885-e089-cb1856631403",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(11.3510, grad_fn=<DivBackward0>)\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 82., 104.],\n",
            "        [117., 143.],\n",
            "        [ 20.,  42.]])\n",
            "tensor([[ 55.3207,  71.8001],\n",
            "        [ 77.0057,  98.0650],\n",
            "        [119.2917, 144.9698],\n",
            "        [ 23.3146,  44.6115]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now I am satisfied with loss @ 11, now time to pass 5th data point\n",
        "inputs=torch.tensor([68,99,74.])\n",
        "predict = model(inputs)\n",
        "loss = mse(predict,targets)\n",
        "print(predict)"
      ],
      "metadata": {
        "id": "tyvz5GSsNtWR",
        "outputId": "ab3fc84e-05b6-457e-e865-663230527c2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([103.2584, 121.1408], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction is very close to target. Great!!!"
      ],
      "metadata": {
        "id": "IL95EdQfPU0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear regression using PyTorch built-ins\n",
        "import torch.nn as nn #PyTorch utility classes for building neural networks"
      ],
      "metadata": {
        "id": "AYd6RIEjO0cN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#taking a bigger data set using numpy and converting to tensors of PyTorch\n",
        "# Input (dim1, dim2, dim3)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')\n",
        "\n",
        "# Targets (Dim1, Dim2)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "metadata": {
        "id": "_d2cxHZIRKy9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to define the dataset\n",
        "from torch.utils.data import TensorDataset\n",
        "train_ds = TensorDataset(inputs,targets)"
      ],
      "metadata": {
        "id": "BRcrfH6-W8BF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to take random batch of given inputs to train the model\n",
        "from torch.utils.data import DataLoader\n",
        "bs = 5\n",
        "train = DataLoader(train_ds,bs,shuffle=True) #enble shuffling to train with random data"
      ],
      "metadata": {
        "id": "6TIuVTrbT4dY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining a model using nn and wirghts & biases intialization\n",
        "model = nn.Linear(3,2)   # 3 inputs and 2 outputs\n",
        "#we can see intialized weights and biases\n",
        "print(model.weight)\n",
        "print(model.bias)\n",
        "#.parameter is also used to call weights and bias from model\n",
        "list(model.parameters())"
      ],
      "metadata": {
        "id": "CdSXJCBJXzXZ",
        "outputId": "ef71d016-5b48-4d42-8d9d-f723fa2e11c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.5067,  0.1565,  0.5292],\n",
            "        [-0.2564, -0.0915,  0.5316]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1942, -0.2274], requires_grad=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.5067,  0.1565,  0.5292],\n",
              "         [-0.2564, -0.0915,  0.5316]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.1942, -0.2274], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# intial prediction\n",
        "preds = model(inputs)\n",
        "preds"
      ],
      "metadata": {
        "id": "bPcRnJCCYZSd",
        "outputId": "8e1f1d83-2097-41d4-8a84-a2b01c00ce5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 70.0382,  -2.2142],\n",
              "        [ 93.5593,   2.4133],\n",
              "        [ 95.5580,  -3.9596],\n",
              "        [ 77.7999, -10.6431],\n",
              "        [ 86.8398,  10.5115],\n",
              "        [ 70.3883,  -2.3791],\n",
              "        [ 93.9320,   3.0365],\n",
              "        [ 96.5939,  -3.6843],\n",
              "        [ 77.4498, -10.4782],\n",
              "        [ 86.8623,  11.2994],\n",
              "        [ 70.4109,  -1.5911],\n",
              "        [ 93.9095,   2.2485],\n",
              "        [ 95.1853,  -4.5827],\n",
              "        [ 77.7774, -11.4311],\n",
              "        [ 86.4897,  10.6763]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not Great. Obviously!"
      ],
      "metadata": {
        "id": "ntzittUzYz6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing nn.fuctional to get fuctions\n",
        "import torch.nn.functional as F\n",
        "loss = F.mse_loss #defining loss function as mean square error\n",
        "losses = loss(model(inputs),targets) #ccalculating loss\n",
        "print(losses)"
      ],
      "metadata": {
        "id": "wgveuOg8Yk8r",
        "outputId": "3240f9a3-fd92-4621-9a7e-29db97b7a6ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5197.2202, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using PyTorch optim defining optimizer model\n",
        "opt = torch.optim.SGD(model.parameters(), lr = 1e-6)   #SGD = Stochastic gradient descent"
      ],
      "metadata": {
        "id": "zKg51K0bYosj"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model and printing every 10th epoch loss\n",
        "#it uses data loaded previous level and all funxtions created above\n",
        "#model, loss, opt\n",
        "def val(num_epochs, model, loss, opt, train):\n",
        "    #Repeat for given number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "      for x,y in train:\n",
        "          # 1. Generating predictions\n",
        "          pred = model(x)\n",
        "          # 2. Calculating loss\n",
        "          losses = loss(pred,y)\n",
        "          # 3. Computing gradients\n",
        "          losses.backward()\n",
        "          # 4. Upating parameters (weights and biases) using SGD\n",
        "          opt.step()\n",
        "          # 5. Resetting the gradients to zero\n",
        "          opt.zero_grad()\n",
        "      #printing the losses for every 10 epoch\n",
        "      if(epoch+1) % 10 ==0:\n",
        "        print('Epoch [{}/{}], Loss: {}'.format(epoch+1,num_epochs,losses.item()))"
      ],
      "metadata": {
        "id": "5OCtEj-DZ2QA"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val(1000,model,loss,opt,train)"
      ],
      "metadata": {
        "id": "tknxiT3EcJgG",
        "outputId": "0c21014c-e5fb-42b5-ed65-c5a63a0b9463",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/1000], Loss: 18.300861358642578\n",
            "Epoch [20/1000], Loss: 5.664689064025879\n",
            "Epoch [30/1000], Loss: 9.919859886169434\n",
            "Epoch [40/1000], Loss: 4.524773597717285\n",
            "Epoch [50/1000], Loss: 3.6833317279815674\n",
            "Epoch [60/1000], Loss: 9.3099365234375\n",
            "Epoch [70/1000], Loss: 11.728381156921387\n",
            "Epoch [80/1000], Loss: 10.106321334838867\n",
            "Epoch [90/1000], Loss: 14.023469924926758\n",
            "Epoch [100/1000], Loss: 13.7827730178833\n",
            "Epoch [110/1000], Loss: 13.824953079223633\n",
            "Epoch [120/1000], Loss: 8.832287788391113\n",
            "Epoch [130/1000], Loss: 11.218454360961914\n",
            "Epoch [140/1000], Loss: 6.14157772064209\n",
            "Epoch [150/1000], Loss: 12.180593490600586\n",
            "Epoch [160/1000], Loss: 4.422818660736084\n",
            "Epoch [170/1000], Loss: 6.061863899230957\n",
            "Epoch [180/1000], Loss: 5.067444801330566\n",
            "Epoch [190/1000], Loss: 4.9310712814331055\n",
            "Epoch [200/1000], Loss: 7.262157440185547\n",
            "Epoch [210/1000], Loss: 9.708313941955566\n",
            "Epoch [220/1000], Loss: 6.693589687347412\n",
            "Epoch [230/1000], Loss: 8.6727933883667\n",
            "Epoch [240/1000], Loss: 7.5333356857299805\n",
            "Epoch [250/1000], Loss: 3.665208101272583\n",
            "Epoch [260/1000], Loss: 4.994089126586914\n",
            "Epoch [270/1000], Loss: 5.936326026916504\n",
            "Epoch [280/1000], Loss: 3.3219592571258545\n",
            "Epoch [290/1000], Loss: 8.510318756103516\n",
            "Epoch [300/1000], Loss: 3.0976507663726807\n",
            "Epoch [310/1000], Loss: 3.302699565887451\n",
            "Epoch [320/1000], Loss: 3.0260136127471924\n",
            "Epoch [330/1000], Loss: 3.7596969604492188\n",
            "Epoch [340/1000], Loss: 2.9434139728546143\n",
            "Epoch [350/1000], Loss: 4.111723899841309\n",
            "Epoch [360/1000], Loss: 6.442191123962402\n",
            "Epoch [370/1000], Loss: 3.00685453414917\n",
            "Epoch [380/1000], Loss: 1.9836196899414062\n",
            "Epoch [390/1000], Loss: 5.550926208496094\n",
            "Epoch [400/1000], Loss: 3.548973560333252\n",
            "Epoch [410/1000], Loss: 4.561621189117432\n",
            "Epoch [420/1000], Loss: 5.194821357727051\n",
            "Epoch [430/1000], Loss: 3.0637056827545166\n",
            "Epoch [440/1000], Loss: 4.678372859954834\n",
            "Epoch [450/1000], Loss: 3.621868848800659\n",
            "Epoch [460/1000], Loss: 2.05379581451416\n",
            "Epoch [470/1000], Loss: 3.546085834503174\n",
            "Epoch [480/1000], Loss: 2.25862193107605\n",
            "Epoch [490/1000], Loss: 2.87684965133667\n",
            "Epoch [500/1000], Loss: 0.8656944036483765\n",
            "Epoch [510/1000], Loss: 2.0189661979675293\n",
            "Epoch [520/1000], Loss: 1.8012733459472656\n",
            "Epoch [530/1000], Loss: 3.980703830718994\n",
            "Epoch [540/1000], Loss: 4.027493953704834\n",
            "Epoch [550/1000], Loss: 2.1921017169952393\n",
            "Epoch [560/1000], Loss: 1.508323073387146\n",
            "Epoch [570/1000], Loss: 1.548851728439331\n",
            "Epoch [580/1000], Loss: 1.5084576606750488\n",
            "Epoch [590/1000], Loss: 4.243638038635254\n",
            "Epoch [600/1000], Loss: 2.018646717071533\n",
            "Epoch [610/1000], Loss: 3.236023426055908\n",
            "Epoch [620/1000], Loss: 2.172330856323242\n",
            "Epoch [630/1000], Loss: 2.1201088428497314\n",
            "Epoch [640/1000], Loss: 2.6511495113372803\n",
            "Epoch [650/1000], Loss: 3.012481927871704\n",
            "Epoch [660/1000], Loss: 2.233612298965454\n",
            "Epoch [670/1000], Loss: 1.8969576358795166\n",
            "Epoch [680/1000], Loss: 2.31162691116333\n",
            "Epoch [690/1000], Loss: 1.4362337589263916\n",
            "Epoch [700/1000], Loss: 3.0979793071746826\n",
            "Epoch [710/1000], Loss: 1.388856291770935\n",
            "Epoch [720/1000], Loss: 1.275499939918518\n",
            "Epoch [730/1000], Loss: 1.538088083267212\n",
            "Epoch [740/1000], Loss: 1.0314744710922241\n",
            "Epoch [750/1000], Loss: 1.6911194324493408\n",
            "Epoch [760/1000], Loss: 2.1671385765075684\n",
            "Epoch [770/1000], Loss: 2.518261671066284\n",
            "Epoch [780/1000], Loss: 1.613273024559021\n",
            "Epoch [790/1000], Loss: 1.5455944538116455\n",
            "Epoch [800/1000], Loss: 2.2925162315368652\n",
            "Epoch [810/1000], Loss: 2.5130488872528076\n",
            "Epoch [820/1000], Loss: 1.1136178970336914\n",
            "Epoch [830/1000], Loss: 0.9561241865158081\n",
            "Epoch [840/1000], Loss: 1.0656921863555908\n",
            "Epoch [850/1000], Loss: 1.0795179605484009\n",
            "Epoch [860/1000], Loss: 1.655837059020996\n",
            "Epoch [870/1000], Loss: 1.5528395175933838\n",
            "Epoch [880/1000], Loss: 1.9938589334487915\n",
            "Epoch [890/1000], Loss: 1.7106590270996094\n",
            "Epoch [900/1000], Loss: 1.57270085811615\n",
            "Epoch [910/1000], Loss: 0.9081939458847046\n",
            "Epoch [920/1000], Loss: 1.5964181423187256\n",
            "Epoch [930/1000], Loss: 1.8917392492294312\n",
            "Epoch [940/1000], Loss: 2.269568681716919\n",
            "Epoch [950/1000], Loss: 1.0555167198181152\n",
            "Epoch [960/1000], Loss: 1.6224219799041748\n",
            "Epoch [970/1000], Loss: 0.7878235578536987\n",
            "Epoch [980/1000], Loss: 1.4370810985565186\n",
            "Epoch [990/1000], Loss: 1.6916277408599854\n",
            "Epoch [1000/1000], Loss: 1.8030402660369873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#comparing predictions and targtets\n",
        "preds = model(inputs)\n",
        "print(preds)\n",
        "print(targets)"
      ],
      "metadata": {
        "id": "FpScmAUJcOF1",
        "outputId": "51570d03-7998-4227-9699-b4792479483c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 57.1583,  70.4669],\n",
            "        [ 81.8314, 100.6035],\n",
            "        [118.3437, 132.5222],\n",
            "        [ 22.1629,  38.3996],\n",
            "        [100.6844, 118.1936],\n",
            "        [ 55.9398,  69.4085],\n",
            "        [ 81.6338, 100.7017],\n",
            "        [118.6194, 133.1329],\n",
            "        [ 23.3814,  39.4579],\n",
            "        [101.7053, 119.3501],\n",
            "        [ 56.9607,  70.5651],\n",
            "        [ 80.6129,  99.5451],\n",
            "        [118.5413, 132.4240],\n",
            "        [ 21.1421,  37.2430],\n",
            "        [101.9029, 119.2519]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.],\n",
            "        [ 57.,  69.],\n",
            "        [ 80., 102.],\n",
            "        [118., 132.],\n",
            "        [ 21.,  38.],\n",
            "        [104., 118.],\n",
            "        [ 57.,  69.],\n",
            "        [ 82., 100.],\n",
            "        [118., 134.],\n",
            "        [ 20.,  38.],\n",
            "        [102., 120.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing with any 1 data point randomly and new one\n",
        "model(torch.tensor([88,134,59.]))"
      ],
      "metadata": {
        "id": "VNGFo7gJc081",
        "outputId": "398a3cae-6ebc-4485-a340-270e88695d3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([118.6194, 133.1329], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.tensor([75,63,44.]))"
      ],
      "metadata": {
        "id": "44KM_G6udL8B",
        "outputId": "361a7238-549a-422a-ad66-f7bee7797129",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([53.6779, 67.6630], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great!!!. It's predicting too good."
      ],
      "metadata": {
        "id": "qhvuyN9Ddfm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Dw2sg6mZdanH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}